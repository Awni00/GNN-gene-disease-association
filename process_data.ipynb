{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat data for PyTorch and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "proteins = pd.read_csv('data/Datasetv1.3.csv', index_col=0)\n",
    "protein_links = pd.read_csv('data/protein_links.csv', index_col=0)\n",
    "\n",
    "# make string_protein_id the index\n",
    "proteins['#string_protein_id'] = proteins['#string_protein_id'].astype(int)\n",
    "proteins = proteins.set_index('#string_protein_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   233,    412,   1008, ..., 485668, 485672, 485678])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find unique proteins in protein_links\n",
    "unique_proteins = np.unique(list(protein_links.protein1) + list(protein_links.protein2))\n",
    "unique_proteins = np.sort(unique_proteins)\n",
    "unique_proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a unique id system starting at 0 (for link list for pytorch, etc...)\n",
    "protein_ids_dict = {id: protein for id, protein in enumerate(unique_proteins)}\n",
    "protein_ids_dict_inv = {protein: id for id, protein in enumerate(unique_proteins)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the link list in this new unique id system\n",
    "link_list = [(protein_ids_dict_inv[p1], protein_ids_dict_inv[p2]) for p1, p2 in zip(protein_links.protein1, protein_links.protein2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the id dictionary and link list\n",
    "np.save('data/protein_ids_dict.npy', protein_ids_dict)\n",
    "np.save('data/link_list.npy', link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate X feature matrix\n",
    "all_features = ['protein_size'] + list(proteins.columns[4:])\n",
    "valid_features = [feature for feature in all_features if (~proteins[feature].isna()).sum() > 1000] # a feature is valid if > 5% of proteins have it\n",
    "\n",
    "# FIXME: currently the feature matrix is mostly NaN's. this is a placeholder while we get a proper protein feature dataset\n",
    "proteins_ = proteins.loc[unique_proteins][all_features].fillna(0) # simply replace NaN's with 0 :(\n",
    "X = proteins_.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/protein_features.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Y labels\n",
    "# FIXME: where do these labels come from?\n",
    "Y = proteins.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/protein_labels.npy', Y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c536624f42ad28a25b71910f95eefc8498c618baf8c306d00b21bed7daec08b1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('projectx': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
